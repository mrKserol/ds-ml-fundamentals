# Gradient Boosting Regressor

В этом разделе реализован алгоритм градиентного бустинга для задачи регрессии.
Основная цель — воспроизвести логику бустинга: последовательное обучение
ансамбля слабых моделей на антиградиентах функции потерь.

Логика бустинга реализована вручную, без использования готовых реализаций
`GradientBoostingRegressor` из `sklearn`.

---

## Постановка задачи

Целевая переменная — количество дней просрочки по кредиту (`delay_days`).

Задача формулируется как **регрессия**, поскольку:
- значения таргета упорядочены,
- имеет смысл расстояние между ними,
- используются стандартные регрессионные функции потерь.

---

## Идея градиентного бустинга

Градиентный бустинг строит ансамбль моделей последовательно.
На каждой итерации новая модель обучается предсказывать **антиградиент**
функции потерь текущего ансамбля.

Для квадратичной ошибки (MSE):

`L(y, y_pred) = (y - y_pred)^2`

Антиградиент по предсказанию:

`-(y_pred - y) = y - y_pred`


Таким образом, на каждой итерации модель обучается на остатках
(`residuals = y_true - y_pred`).

---

## Реализация

В данной реализации:

- тип задачи: регрессия
- функция потерь: **Mean Squared Error (MSE)**
- базовый алгоритм: `sklearn.tree.DecisionTreeRegressor`
- стратегия ансамблирования: **gradient boosting**
- обновление предсказаний на каждой итерации:

`y_pred_{t+1} = y_pred_t + learning_rate * f_t(x)`
где `learning_rate` — коэффициент шага обновления,
а `f_t(x)` — предсказание базовой модели на t-й итерации.

### Параметры модели
- `n_estimators` — число итераций бустинга
- `learning_rate` — шаг обновления предсказаний
- `max_depth` — глубина базовых деревьев
- `min_samples_split` — минимальное число объектов для разбиения

---

## Проверка корректности

Корректность реализации проверялась сравнением с
`sklearn.GradientBoostingRegressor` при одинаковых гиперпараметрах.

Использовались следующие критерии:
- сравнение метрик качества (MSE, MAE),
- визуальный анализ предсказаний,
- проверка численного расхождения предсказаний.

Незначительные различия в предсказаниях объясняются:
- разным выбором порогов разбиений в деревьях,
- численными эффектами,
- порядком вычислений.

При этом значения метрик отличаются несущественно,
что подтверждает эквивалентность реализованного алгоритма.

---

## Визуальный анализ

Для оценки качества модели использовались:
- график зависимости `y_true` vs `y_pred`,
- распределение ошибок (residuals),

---

## Содержимое папки

- [gradientboosting.py](gradientboosting.py)  
  Реализация градиентного бустинга и логики обновления предсказаний.

- [gradient_boosting.ipynb](gradient_boosting.ipynb)  
  Пошаговый разбор алгоритма, обучение модели, сравнение со `sklearn`
  и визуальный анализ результатов.

- [users.csv](users.csv)  
  Датасет с признаками и целевой переменной — количеством дней просрочки.

---

## Замечания

Реализация ориентирована на учебные и исследовательские цели.
Для практических задач предпочтительны оптимизированные библиотеки
(XGBoost, LightGBM, CatBoost), однако понимание базовой логики бустинга
является критически важным для работы с ансамблевыми методами.

Данный модуль демонстрирует полный цикл построения градиентного бустинга
для регрессии и позволяет проследить алгоритм шаг за шагом.
