# Метрики классификации

В этом разделе рассматриваются базовые метрики качества бинарной классификации
и их связь с матрицей ошибок (confusion matrix).

Основной фокус сделан на понимании того,
**какие типы ошибок отражает каждая метрика**
и почему выбор метрики зависит от постановки задачи.

---

## Содержимое

### 1) Базовые метрики классификации
**Файл:** [basic_metrics.ipynb](basic_metrics.ipynb)

В ноутбуке реализованы и разобраны следующие метрики:
- **Accuracy**
- **Precision**
- **Recall**
- **F1-score**

Метрики сначала вычисляются вручную на основе значений
TP, FP, FN и TN, после чего результаты сравниваются
с реализациями из библиотеки `sklearn.metrics`.

---

## Ключевые идеи

- Все метрики классификации напрямую выводятся из матрицы ошибок.
- Accuracy может быть некорректной метрикой при дисбалансе классов,
  так как не учитывает структуру ошибок.
- Precision и recall отражают разные типы рисков и находятся
  в компромиссном соотношении.
- F1-score используется как компромиссная метрика,
  позволяющая учитывать одновременно precision и recall.

---

## Визуализация

В ноутбуке используются визуализации:
- **Confusion Matrix** — для наглядного представления TP / FP / FN / TN
- **Precision / Recall / F1 vs Threshold** — для демонстрации влияния порога классификации
  и компромисса между метриками

Визуализации помогают связать формулы метрик
с практическими последствиями изменения порога.

---

## Используемые инструменты

- NumPy
- scikit-learn
- Matplotlib

---

## Практическое замечание

Выбор метрики классификации должен определяться требованиями задачи
и стоимостью различных типов ошибок,
а не универсальным правилом или одной «лучшей» метрикой.
